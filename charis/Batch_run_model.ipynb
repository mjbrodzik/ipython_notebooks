{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Runs the ti_melt model for a set of drainageIDs and years</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%pylab notebook\n",
    "import datetime as dt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "from charistools.hypsometry import Hypsometry\n",
    "from charistools.meltModels import TriSurfTempIndexMelt\n",
    "from charistools.meltModels import ImshowTriSurfMelt\n",
    "from charistools.meltModels import PlotTriSurfInput\n",
    "from charistools.meltModels import PlotTriSurfMelt\n",
    "from charistools.modelEnv import ModelEnv\n",
    "from charistools.timeSeries import TimeSeries\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best set of 20 models for each calibration basin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/work/charis/ti_model/calibrations_correct_cost'\n",
    "nstrikes = 2\n",
    "params = \"DDFnbr=10mm_N100_M050\"\n",
    "calibrationID = \"AM_Vakhsh_at_Komsomolabad\"\n",
    "best_models_file = \"%s/%s.%dstr_%s.stats.best20.dat\" % (dir, calibrationID, nstrikes, params)\n",
    "best_df = pd.read_pickle(best_models_file)\n",
    "print(\"best model 0 : %s\" % best_df.iloc[0].model)\n",
    "print(\"best model 10: %s\" % best_df.iloc[10].model)\n",
    "print(\"best model 19: %s\" % best_df.iloc[19].model)\n",
    "best_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the config setter to get the overall best model from all models tested in Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_config_for_model_type(drainageID, nstrikes):\n",
    "    '''\n",
    "    Sets up model config for best model associated with this basin and nstrikes data\n",
    "        drainageID : name of drainage where the model will be run, XX_river_at_pourpoint\n",
    "        nstrikes : 2 or 3 (MODICE strikes)\n",
    "    Returns a dict with:\n",
    "        env : charis model config file\n",
    "        model : string with model to run, either \"Best\" or from the requested SA cycle\n",
    "        label : string to use for output filenames\n",
    "    '''\n",
    "    #on summit for partner basins\n",
    "    configFile = '/projects/brodzik/charis_ti_melt/partner_basins_modelEnv_config.ini'\n",
    "    #on summit for all basins used in REEC paper\n",
    "    #configFile = '/projects/brodzik/ipython_notebooks/charis/calibration_modelEnv_config.ini'\n",
    "    myEnv = ModelEnv(tileConfigFile=configFile)\n",
    "    \n",
    "    # parse the drainageID to decide on the best calibration basin models to use\n",
    "    majorID = drainageID[:2]\n",
    "    if majorID == \"IN\":\n",
    "        calibrationID = \"IN_Hunza_at_DainyorBridge\"\n",
    "    elif majorID == \"AM\":\n",
    "        calibrationID = \"AM_Vakhsh_at_Komsomolabad\"\n",
    "    elif majorID == \"SY\":\n",
    "        calibrationID = \"SY_Naryn_at_NarynTown\"\n",
    "    elif drainageID == \"GA_Narayani_at_Devghat\":\n",
    "        calibrationID = drainageID\n",
    "    elif drainageID == \"GA_Karnali_at_Benighat\":\n",
    "        calibrationID = drainageID\n",
    "    elif drainageID == \"GA_SaptaKosi_at_Chatara\":\n",
    "        calibrationID = drainageID\n",
    "    elif majorID == \"GA\":\n",
    "        calibrationID = \"GA_Karnali_at_Benighat\"\n",
    "    elif majorID == \"BR\":\n",
    "        calibrationID = \"GA_SaptaKosi_at_Chatara\"\n",
    "    elif majorID == \"BL\":\n",
    "        calibrationID = \"SY_Naryn_at_NarynTown\"\n",
    "    else:\n",
    "        raise ValueError(\"ERROR: Skipping drainageID=%s, unknown majorID=%s\" % (drainageID, majorID))\n",
    "    \n",
    "    # Parse for the calibration basin short name\n",
    "    p = re.compile(r\"[A-Z]{2}_([A-Za-z]+)_\")\n",
    "    m = p.search(calibrationID)\n",
    "    shortName = m.group(1)\n",
    "    label = \"best_%s_SA_model\" % shortName\n",
    "\n",
    "    melt_type = ['snow_on_land_melt_by_elevation',\n",
    "                 'snow_on_ice_melt_by_elevation',\n",
    "                 'exposed_glacier_ice_melt_by_elevation']\n",
    "    \n",
    "    # Set calibration_dir to the one in /pl/active/charis/\n",
    "    calibration_dir = \"/pl/active/charis/ti_model/calibrations_correct_cost\"\n",
    "\n",
    "    # Use the best overall model, get it from the models file with best models\n",
    "    # by drainage and nstrikes\n",
    "    print(\"Prepping for drainageID=%s\" % (drainageID), file=sys.stderr)\n",
    "        \n",
    "    params = \"DDFnbr=10mm_N100_M050\"\n",
    "    models_file = \"%s/%s.%dstr_%s.stats.best20.dat\" % (calibration_dir, \n",
    "                                                       calibrationID, nstrikes, params)\n",
    "    best_df = pd.read_pickle(models_file)\n",
    "    # index 0 in this file is the best overall model\n",
    "    model_str = best_df.iloc[0].model\n",
    "        \n",
    "    print(\"Using models from %s\" % models_file, file=sys.stderr)\n",
    "    print(\"best model 0 : %s\" % model_str)\n",
    "    #print(\"Output locations will be:\", file=sys.stderr)\n",
    "    #for i in melt_type:\n",
    "    #    print(\"%s: %s\" % (i, myEnv.tileConfig['hypsometry'][i]['dir']), file=sys.stderr)\n",
    "        \n",
    "    out = {'env':myEnv,\n",
    "           'majorID':majorID,\n",
    "           'calibrationID':calibrationID,\n",
    "           'model_str':model_str,\n",
    "           'label':label}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These are best models for 2strike inputs used in REEC paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = ['SY_Naryn', 'AM_Vakhsh', 'IN_Hunza', 'GA_Karnali', 'BR_SaptaKosi']\n",
    "for id in ids:\n",
    "    out = prep_config_for_model_type(id, 2)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of all OBJECTID basins\n",
    "#%cd /Users/brodzik/projects/CHARIS/derived_hypsometries/MODSCAG_GF_v09_fromFile_MERRA_less_ET/\n",
    "%cd /work/charis/ti_model/derived_hypsometries/MODSCAG_GF_v09_fromFile/\n",
    "#majorBasinIDs = ['AM', 'BR','GA_v01', 'IN_v01', 'SY_v01']\n",
    "majorBasinIDs = ['BR']\n",
    "drainageIDs = []\n",
    "for id in majorBasinIDs:\n",
    "    ids = glob.glob(\"%s_OBJECTID*\" % id)\n",
    "    ids.sort()\n",
    "    drainageIDs = drainageIDs + ids\n",
    "    print(\"There are %d sub-basins for the %s major basin\" % (len(ids), id))\n",
    "\n",
    "len(drainageIDs)\n",
    "drainageIDs\n",
    "\n",
    "drainageIDs = drainageIDs[-4:-1]\n",
    "drainageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = ['Astore', 'DrasNala', 'Gilgit', 'Hunza', 'Kharmong', 'Shigar', 'Shyok', 'Tarbela', 'Zanskar']\n",
    "#names = ['10']\n",
    "#names = ['Tarbela']\n",
    "#drainageIDs = [\"IN_OBJECTID%s\" % name for name in names]\n",
    "#drainageIDs = [\"IN_Hunza_at_DainyorBridge\", \n",
    "#               \"AM_Vakhsh_at_Komsomolabad\", \n",
    "#               \"SY_Naryn_at_NarynTown\", \n",
    "#               \"GA_SaptaKosi_at_Chatara\",\n",
    "#               #\"GA_Narayani_at_Devghat\",\n",
    "#               \"GA_Karnali_at_Benighat\"]\n",
    "drainageIDs = [\"AM_Vakhsh_at_Komsomolabad\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of all partner basins\n",
    "%cd /scratch/summit/brodzik/ti_model/basins/partner_basins\n",
    "drainageIDs = glob.glob(\"AM_*_at_*\")\n",
    "drainageIDs.sort()\n",
    "print(\"There are %d partner basins in this batch\" % (len(drainageIDs)))\n",
    "\n",
    "drainageIDs = drainageIDs[-6:-5]\n",
    "drainageIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_method = 'grsize_scag'\n",
    "threshold = 'fromFile'\n",
    "nstrikes = 2\n",
    "\n",
    "years = np.arange(14) + 2001\n",
    "#years = np.arange(1) + 2001\n",
    "#years = np.arange(7) + 2001\n",
    "#years = np.arange(7) + 2008\n",
    "\n",
    "DDF_annotation = True\n",
    "show_rainfall = False\n",
    "rainfall_col = 'diff_km3'\n",
    "show_runoff = False\n",
    "\n",
    "closePlot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(myEnv, drainageID, year=2001, nstrikes=3, ablation_method='grsize_scag', threshold=205, \n",
    "              model_str=\"8.67_8.67_10.0_17.0\", label='best_model'):\n",
    "    input = myEnv.model_inputs(drainageID=drainageID,\n",
    "                               year=year,\n",
    "                               modice_nstrikes=nstrikes,\n",
    "                               ablation_method=ablation_method,\n",
    "                               threshold=threshold)\n",
    "\n",
    "    (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf) = model_str.split(\"_\")\n",
    "    min_snow_ddf = float(min_snow_ddf)\n",
    "    max_snow_ddf = float(max_snow_ddf)\n",
    "    min_ice_ddf = float(min_ice_ddf)\n",
    "    max_ice_ddf = float(max_ice_ddf)\n",
    "    \n",
    "    (SOLmelt, SOImelt, EGImelt) = TriSurfTempIndexMelt(\n",
    "        input['snow_on_land_by_elevation_filename'],\n",
    "        input['snow_on_ice_by_elevation_filename'],\n",
    "        input['exposed_glacier_ice_by_elevation_filename'],\n",
    "        input['temperature_by_elevation_filename'],\n",
    "        min_snow_ddf=min_snow_ddf,\n",
    "        max_snow_ddf=max_snow_ddf,\n",
    "        min_ice_ddf=min_ice_ddf,\n",
    "        max_ice_ddf=max_ice_ddf)\n",
    "    \n",
    "    SOLmeltfile = myEnv.hypsometry_filename(\n",
    "        type='snow_on_land_melt_by_elevation',\n",
    "        drainageID=drainageID,\n",
    "        year=year,\n",
    "        modice_nstrikes=nstrikes,\n",
    "        ablation_method=ablation_method,\n",
    "        threshold=threshold)\n",
    "    SOImeltfile = myEnv.hypsometry_filename(\n",
    "        type='snow_on_ice_melt_by_elevation',\n",
    "        drainageID=drainageID,\n",
    "        year=year,\n",
    "        modice_nstrikes=nstrikes,\n",
    "        ablation_method=ablation_method,\n",
    "        threshold=threshold)\n",
    "    EGImeltfile = myEnv.hypsometry_filename(\n",
    "        type='exposed_glacier_ice_melt_by_elevation',\n",
    "        drainageID=drainageID,\n",
    "        year=year,\n",
    "        modice_nstrikes=nstrikes,\n",
    "        ablation_method=ablation_method,\n",
    "        threshold=threshold)\n",
    "    SOLmeltfile = SOLmeltfile.replace('_by_elev.', '_by_elev.' + label + '.')\n",
    "    SOImeltfile = SOImeltfile.replace('_by_elev.', '_by_elev.' + label + '.')\n",
    "    EGImeltfile = EGImeltfile.replace('_by_elev.', '_by_elev.' + label + '.')\n",
    "\n",
    "    columns = [float(i) for i in SOLmelt.data.columns]\n",
    "    SOLmelt.data.columns = columns\n",
    "    SOLmelt.data = SOLmelt.data[sort(columns)]\n",
    "\n",
    "    # Temporary fix for SOLmelt.data NaNs\n",
    "    SOLmelt.data = SOLmelt.data.fillna(value=0.)\n",
    "\n",
    "    columns = [float(i) for i in SOImelt.data.columns]\n",
    "    SOImelt.data.columns = columns\n",
    "    SOImelt.data = SOImelt.data[sort(columns)]\n",
    "\n",
    "    columns = [float(i) for i in EGImelt.data.columns]\n",
    "    EGImelt.data.columns = columns\n",
    "    EGImelt.data = EGImelt.data[sort(columns)]\n",
    "\n",
    "    SOLmelt.write(filename=SOLmeltfile, decimal_places=6)\n",
    "    SOImelt.write(filename=SOImeltfile, decimal_places=6)\n",
    "    EGImelt.write(filename=EGImeltfile, decimal_places=6)\n",
    "    \n",
    "    print(\"%s : %d : model=%s\" % (drainageID, year, model_str))\n",
    "    \n",
    "    baseFilename = SOImeltfile\n",
    "    p = re.compile(r'snow_on_ice.+')\n",
    "    baseFilename = p.sub('', baseFilename)\n",
    "    \n",
    "    return(baseFilename, input, model_str, SOLmelt, SOImelt, EGImelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_isotherm(ax, x, y, color):\n",
    "    orig_ylim = ax.get_ylim()\n",
    "    ax.plot(x, y, c=color)\n",
    "    ax.set_ylim(orig_ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_melt_hyps(drainageID, year, baseFilename, temperatureFilename,\n",
    "                   SOLmelt, SOImelt, EGImelt, label='best_model', closePlot=True):\n",
    "    \n",
    "    year_str = str(year)\n",
    "    fig, axes = plt.subplots(4,1, figsize=(8,10))\n",
    "    \n",
    "    # If SOLmelt is non-empty, but SOImelt and SGImelt are empty,\n",
    "    # then make a copy of the dimensions of SOLmelt that is filled with zeroes\n",
    "    if not SOLmelt.data.empty and SOImelt.data.empty and EGImelt.data.empty:\n",
    "        SOImelt.data = SOLmelt.data.copy()\n",
    "        SOImelt.data[:] = 0.\n",
    "        EGImelt.data = SOLmelt.data.copy()\n",
    "        EGImelt.data[:] = 0.\n",
    "        \n",
    "    if not SOLmelt.data.empty and not SOImelt.data.empty and not EGImelt.data.empty:\n",
    "        ImshowTriSurfMelt(axes[:3], SOLmelt, SOImelt, EGImelt)\n",
    "    else:\n",
    "        axes[0].annotate('no melt data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        axes[0].set_title('Snow-on-Ice Melt')\n",
    "        axes[1].annotate('no melt data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        axes[1].set_title('Exposed-Glacier-Ice Melt')\n",
    "        axes[2].annotate('no melt data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        axes[2].set_title('Snow-on-Land Melt')\n",
    "         \n",
    "    # Fetch the temperature data hypsometry\n",
    "    temperatureHyps = Hypsometry(temperatureFilename)\n",
    "    if not temperatureHyps.data.empty:\n",
    "        temperatureHyps.data.replace(to_replace='--', value=0.0, inplace=True)\n",
    "        axes[3] = temperatureHyps.imshow(ax=axes[3], title='Temperature',\n",
    "                                         vmin=-45, vmax=45, cmap='RdGy_r'\n",
    "                                         )\n",
    "    else:\n",
    "        axes[3].annotate('no data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        axes[3].set_title('Temperature')\n",
    "        \n",
    "    for ax in axes:\n",
    "        ax.set_title(drainageID + \" (\" + year_str + \") \" + ax.get_title())\n",
    "        \n",
    "    if not temperatureHyps.data.empty:\n",
    "        \n",
    "        # Add a zero-degree isotherm line to each of the melt plots\n",
    "        # Find elevation of zero-degree isotherm\n",
    "        # Default is the highest elevation\n",
    "        zero_isotherm_elevations = np.full(len(temperatureHyps.data.index),\n",
    "                                           float(temperatureHyps.data.columns[-1]))\n",
    "        for i, d in enumerate(temperatureHyps.data.index):\n",
    "            neg_temps = temperatureHyps.data.loc[d][temperatureHyps.data.loc[d] < 0]\n",
    "            if len(neg_temps) > 0:\n",
    "                zero_isotherm_elevations[i] = float(neg_temps.index[0])\n",
    "                                       \n",
    "        # zero_isotherm_elevations = [\n",
    "        # float(temperatureHyps.data.loc[d][temperatureHyps.data.loc[d] < 0].index[0]) \n",
    "        # for d in temperatureHyps.data.index]\n",
    "        zero_isotherm_x = temperatureHyps.data.index\n",
    "        isotherm_color = (0.8, 0.8, 0.8)\n",
    "        add_isotherm(axes[0], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "        add_isotherm(axes[1], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "        add_isotherm(axes[2], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "        add_isotherm(axes[3], zero_isotherm_x, zero_isotherm_elevations, isotherm_color)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    outfile = baseFilename + label + '.melt_hyps.png'\n",
    "    fig.savefig(outfile)\n",
    "    print(\"Wrote melt_hyps to %s\" % outfile)\n",
    "    if (closePlot):\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_melt_tseries(myEnv, drainageID, year, baseFilename, input, model_str,\n",
    "                      SOLmelt, SOImelt, EGImelt,\n",
    "                      label='best_model',\n",
    "                      DDF_annotation=True, show_rainfall=False, rainfall_col=None, \n",
    "                      show_runoff=False,\n",
    "                      closePlot=True):\n",
    "    year_str = str(year)\n",
    "    (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf) = model_str.split(\"_\")\n",
    "    min_snow_ddf = float(min_snow_ddf)\n",
    "    max_snow_ddf = float(max_snow_ddf)\n",
    "    min_ice_ddf = float(min_ice_ddf)\n",
    "    max_ice_ddf = float(max_ice_ddf)\n",
    "    \n",
    "    melt_by_doy = (SOLmelt.data_by_doy() +\n",
    "                   SOImelt.data_by_doy() +\n",
    "                   EGImelt.data_by_doy())\n",
    "    total_melt = melt_by_doy.sum()\n",
    "    print(\"total melt = %.2f\" % total_melt, file=sys.stderr)\n",
    "    \n",
    "    fig, ax = plt.subplots(3,1,figsize=(9,9))\n",
    "    \n",
    "    if melt_by_doy.empty:\n",
    "        ax[0].annotate('no data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        ax[1].annotate('no data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        ax[2].annotate('no data', xy=(0.5, 0.5), xytext=(0.5, 0.5))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        melt_by_month = melt_by_doy.groupby([pd.TimeGrouper('M')]).sum().to_frame(name='melt')\n",
    "\n",
    "        yyyymm_index = pd.to_datetime(melt_by_month.index.map(lambda x: x.strftime('%Y-%m-15')))\n",
    "        df = pd.DataFrame(data=melt_by_month.values, index=yyyymm_index, columns=['melt'])\n",
    "        df['SOLmelt'] = SOLmelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "        df['SOImelt'] = SOImelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "        df['EGImelt'] = EGImelt.data_by_doy().groupby([pd.TimeGrouper('M')]).sum().values\n",
    "    \n",
    "        left_ax, right_ax = PlotTriSurfInput(\n",
    "            ax[0], \n",
    "            input['snow_on_land_by_elevation_hyps'],\n",
    "            input['snow_on_ice_by_elevation_hyps'],\n",
    "            input['exposed_glacier_ice_by_elevation_hyps'],\n",
    "            input['temperature_by_elevation_hyps'],\n",
    "            temperature_color=(0.7, 0.7, 0.7),\n",
    "            title=\"Inputs for %s (%d)\" % (drainageID, year))\n",
    "    \n",
    "        h, l = left_ax.get_legend_handles_labels()                                       \n",
    "        h1, l1 = right_ax.get_legend_handles_labels()                                    \n",
    "        left_ax.legend(h+h1, l+l1, framealpha=0.5, loc='upper right') \n",
    "        #left_ax.legend(framealpha=0.5)\n",
    "        ax[1] = PlotTriSurfMelt(\n",
    "            ax[1], \n",
    "            SOLmelt, \n",
    "            SOImelt, \n",
    "            EGImelt, \n",
    "            title=\"Modelled melt for %s (%d)\" % (drainageID, year))\n",
    "        ax[1].legend(framealpha=0.5, loc='upper right')\n",
    "        if DDF_annotation:\n",
    "            ax[1].text(ax[1].get_xlim()[0] + (0.03 * (ax[1].get_xlim()[1] - ax[1].get_xlim()[0])), \n",
    "                       ax[1].get_ylim()[1] * 0.7,\n",
    "                       'snow DDF = %.2f - %.2f $mm/C/day$\\nice DDF = %.2f - %.2f $mm/C/day$' % \n",
    "                       (min_snow_ddf, max_snow_ddf, min_ice_ddf, max_ice_ddf),\n",
    "                       style='italic',\n",
    "                       bbox={'facecolor':'gray', 'alpha':0.1, 'pad':10})\n",
    "    \n",
    "        # Get the line colors used by PlotTriSurfMelt\n",
    "        lines = ax[1].get_lines()\n",
    "        SOIcolor = lines[1].get_color()\n",
    "        EGIcolor = lines[2].get_color()\n",
    "        SOLcolor = lines[3].get_color()\n",
    "\n",
    "        title = \"Melt\"\n",
    "        right_bar_list = ['EGImelt', 'SOImelt', 'SOLmelt']\n",
    "        right_bar_colors = [ EGIcolor, SOIcolor, SOLcolor ]\n",
    "        right_bar_title = \"melt\"\n",
    "        right_bar_sum = df[\"melt\"].sum()\n",
    "        ylim = np.amax(df[\"melt\"])\n",
    "        ylim_min = 0.\n",
    "    \n",
    "        # Fetch rainfall and/or runoff, if requested\n",
    "        have_et = False\n",
    "        if show_rainfall:\n",
    "        \n",
    "            rainfallFile = myEnv.calibration_filename(type=\"rainfall\", drainageID=drainageID)\n",
    "            rainfall = TimeSeries(rainfallFile)\n",
    "            monthly_rainfall = rainfall.data['rainfall'][year_str + '-01-01':year_str + '-12-01']\n",
    "            monthly_et = rainfall.data['et_km3'][year_str + '-01-01':year_str + '-12-01']\n",
    "        \n",
    "            rainfall_label = \"rainfall\"\n",
    "            et_label = \"ET\"\n",
    "            \n",
    "            if 0 < len(monthly_rainfall.index):\n",
    "                df[rainfall_label] = monthly_rainfall.values\n",
    "            else:\n",
    "                df[rainfall_label] = np.nan\n",
    "            \n",
    "            if 0 < len(monthly_et.index):\n",
    "                df[et_label] = -1 * monthly_et.values\n",
    "                have_et = True\n",
    "            else:\n",
    "                df[et_label] = np.nan\n",
    "            \n",
    "            rainfallcolor = 'c'\n",
    "            right_bar_list = [rainfall_label] + right_bar_list\n",
    "            right_bar_colors = [ rainfallcolor ] + right_bar_colors\n",
    "            # The following will ignore any NaNs and just return\n",
    "            # the operation using the non-NaN values:\n",
    "            ylim = np.amax(df[[\"melt\", rainfall_label]].sum(axis=1))\n",
    "            title = rainfall_label + \" + Melt\"\n",
    "            right_bar_title = 'melt + ' + rainfall_label\n",
    "            right_bar_sum = df[[\"melt\", rainfall_label]].sum(axis=1).sum()\n",
    "            \n",
    "            if have_et:\n",
    "                etcolor = (0.8, 0.8, 0.8)\n",
    "                et_bar_list = [\"ET\"]\n",
    "                et_bar_colors = [ etcolor ]\n",
    "                ylim_min = df.ET.min()\n",
    "                title = \"%s - ET\" % title\n",
    "                right_bar_title = \"%s - ET\" % right_bar_title\n",
    "                right_bar_sum = right_bar_sum + df[[et_label]].sum(axis=1).sum()\n",
    "            \n",
    "        monthly_annotation = '%s = %.2f $km^3$' % (right_bar_title, right_bar_sum)\n",
    "        if show_runoff:\n",
    "            runoffFile = myEnv.calibration_filename(type=\"runoff\", drainageID=drainageID)\n",
    "            runoff = TimeSeries(runoffFile)\n",
    "            monthly_runoff = runoff.data['runoff'][year_str + '-01-01':year_str + '-12-01']\n",
    "            if 0 < len(monthly_runoff.index) and np.amax(monthly_runoff.values) >= 0.:\n",
    "                df[\"runoff\"] = monthly_runoff.values\n",
    "                max_runoff = np.amax(df[\"runoff\"])\n",
    "            else:\n",
    "                df[\"runoff\"] = np.nan\n",
    "                max_runoff = 0\n",
    "            \n",
    "            runoffcolor = (0.4, 0.4, 0.4)\n",
    "            ylim = np.amax([ylim, max_runoff])\n",
    "            title = \"Runoff vs. \" + title\n",
    "            df[[\"runoff\"]].plot(ax=ax[2], kind=\"bar\",\n",
    "                                edgecolor=(0.9, 0.9, 0.9),\n",
    "                                color=[runoffcolor])\n",
    "            monthly_annotation = '%s = %.2f $km^3$\\nrunoff = %.2f $km^3$' % (\n",
    "                right_bar_title, right_bar_sum, df[\"runoff\"].sum())\n",
    "    \n",
    "        df[right_bar_list].plot(ax=ax[2], \n",
    "                                stacked=True, kind=\"bar\", \n",
    "                                position=0.,\n",
    "                                edgecolor=(0.9, 0.9, 0.9),\n",
    "                                color=right_bar_colors)\n",
    "        if have_et:\n",
    "            df[et_bar_list].plot(ax=ax[2],\n",
    "                                 kind=\"bar\",\n",
    "                                 position=0.0,\n",
    "                                 edgecolor=(0.9, 0.9, 0.9),\n",
    "                                 color=et_bar_colors)\n",
    "            ax[2].axhline(c=(0.7, 0.7, 0.7))\n",
    "        ax[2].set_title(\"Monthly \" + title)\n",
    "        ax[2].set_ylabel('Volume (' + r'$km^3$' + ')') \n",
    "        ax[2].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        for container in ax[2].containers:\n",
    "            plt.setp(container, width=0.25)\n",
    "        ax[2].set_ylim([1.1 * ylim_min, 1.1 * ylim])\n",
    "        ax[2].text(ax[2].get_xlim()[0] + (0.03 * (ax[2].get_xlim()[1] - ax[2].get_xlim()[0])),\n",
    "                   ax[2].get_ylim()[1] * 0.7,\n",
    "                   monthly_annotation,\n",
    "                   style='italic',\n",
    "                   bbox={'facecolor':'gray', 'alpha':0.1, 'pad':10})\n",
    "        handles, labels = ax[2].get_legend_handles_labels()\n",
    "        # ax[2].legend(reversed(handles), reversed(labels), loc='upper right')\n",
    "        ax[2].legend(loc='upper right')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    outfile = baseFilename + label + '.melt_tseries.png'\n",
    "    fig.savefig(outfile)\n",
    "    print(\"Wrote melt_tseries to %s\" % outfile)\n",
    "    if (closePlot):\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drainageIDs, years, nstrikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for drainageID in drainageIDs:\n",
    "    \n",
    "    out = prep_config_for_model_type(drainageID, nstrikes)\n",
    "\n",
    "    print(\"drainageID=%s, majorID=%s, nstrikes=%d, model=%s, label=%s\\n\" % (\n",
    "        drainageID, out['majorID'], nstrikes, out['model_str'], out['label']),\n",
    "          file=sys.stderr)\n",
    "    \n",
    "    for year in years:      \n",
    "        (baseFilename, input, out['model_str'], SOLmelt, SOImelt, EGImelt) = run_model(\n",
    "            out['env'],\n",
    "            drainageID=drainageID, year=year, nstrikes=nstrikes,\n",
    "            ablation_method=ablation_method, threshold=threshold,\n",
    "            model_str=out['model_str'], label=out['label'])\n",
    "        show_melt_hyps(drainageID, year, baseFilename, input['temperature_by_elevation_filename'],\n",
    "                       SOLmelt, SOImelt, EGImelt, label=out['label'], closePlot=closePlot)\n",
    "        show_melt_tseries(out['env'], drainageID, year, baseFilename, input, out['model_str'], \n",
    "                          SOLmelt, SOImelt, EGImelt, label=out['label'],\n",
    "                          DDF_annotation=DDF_annotation, \n",
    "                          show_rainfall=show_rainfall,\n",
    "                          rainfall_col=rainfall_col,\n",
    "                          show_runoff=show_runoff,\n",
    "                          closePlot=closePlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = Hypsometry(filename=\"/Users/brodzik/projects/CHARIS/derived_hypsometries/modscag_gf_grsize_scag/IN_OBJECTID10/IN_OBJECTID10.2001.0100m.ERA_Interim_downscale_uncorrected_tsurf.v0.2_by_elev.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior to QC Best 2 strike models\n",
    "<ul>\n",
    "<li>drainageID=IN_Hunza_at_DainyorBridge, majorID=IN, nstrikes=2, model=10.41_10.48_37.94_42.30, label=best_Hunza_SA_model\n",
    "<li>drainageID=AM_Vakhsh_at_Komsomolabad, majorID=AM, nstrikes=2, model=2.38_4.86_55.86_56.94, label=best_Vakhsh_SA_model\n",
    "<li>drainageID=SY_Naryn_at_NarynTown, majorID=SY, nstrikes=2, model=4.61_5.49_53.30_57.16, label=best_Naryn_SA_model\n",
    "<li>drainageID=GA_SaptaKosi_at_Chatara, majorID=GA, nstrikes=2, model=32.98_33.09_35.52_49.53, label=best_SaptaKosi_SA_model\n",
    "<li>drainageID=GA_Narayani_at_Devghat, majorID=GA, nstrikes=2, model=33.72_33.87_53.36_55.51, label=best_Narayani_SA_model\n",
    "<li>drainageID=GA_Karnali_at_Benighat, majorID=GA, nstrikes=2, model=17.42_17.60_57.32_57.41, label=best_Karnali_SA_model\n",
    "<li>drainageID=GA_v01_OBJECTID1, majorID=GA, nstrikes=2, model=17.42_17.60_57.32_57.41, label=best_Karnali_SA_model\n",
    "<li>drainageID=BR_OBJECTID100, majorID=BR, nstrikes=2, model=32.98_33.09_35.52_49.53, label=best_SaptaKosi_SA_model\n",
    "</ul> \n",
    "\n",
    "# Low (-1std)\n",
    "<ul>\n",
    "<li>drainageID=IN_Hunza_at_DainyorBridge, majorID=IN, nstrikes=2, model=7.00_8.41_26.59_31.55, label=best_Hunza_SA_model\n",
    "<li>drainageID=AM_Vakhsh_at_Komsomolabad, majorID=AM, nstrikes=2, model=0.86_3.19_39.00_45.10, label=best_Vakhsh_SA_model\n",
    "<li>drainageID=SY_Naryn_at_NarynTown, majorID=SY, nstrikes=2, model=2.77_3.22_36.77_48.02, label=best_Naryn_SA_model\n",
    "<li>drainageID=GA_SaptaKosi_at_Chatara, majorID=GA, nstrikes=2, model=29.62_31.57_27.89_44.39, label=best_SaptaKosi_SA_model\n",
    "<li>drainageID=GA_Narayani_at_Devghat, majorID=GA, nstrikes=2, model=28.37_31.42_45.37_49.52, label=best_Narayani_SA_model\n",
    "<li>drainageID=GA_Karnali_at_Benighat, majorID=GA, nstrikes=2, model=13.71_15.75_46.65_50.88, label=best_Karnali_SA_model\n",
    "<li>drainageID=GA_v01_OBJECTID1, majorID=GA, nstrikes=2, model=13.71_15.75_46.65_50.88, label=best_Karnali_SA_model\n",
    "<li>drainageID=BR_OBJECTID100, majorID=BR, nstrikes=2, model=29.62_31.57_27.89_44.39, label=best_SaptaKosi_SA_model\n",
    "</ul>\n",
    "\n",
    "# Some of these changed with QC High (+1std)\n",
    "<ul>\n",
    "<li>drainageID=IN_Hunza_at_DainyorBridge, majorID=IN, nstrikes=2, model=13.82_12.55_49.29_53.05, label=best_Hunza_SA_model\n",
    "<li>drainageID=AM_Vakhsh_at_Komsomolabad, majorID=AM, nstrikes=2, model=3.90_6.53_72.72_68.78, label=best_Vakhsh_SA_model\n",
    "<li>drainageID=SY_Naryn_at_NarynTown, majorID=SY, nstrikes=2, model=6.45_7.76_69.83_66.30, label=best_Naryn_SA_model\n",
    "<li>drainageID=GA_SaptaKosi_at_Chatara, majorID=GA, nstrikes=2, model=36.34_34.61_43.15_54.67, label=best_SaptaKosi_SA_model\n",
    "<li>drainageID=GA_Narayani_at_Devghat, majorID=GA, nstrikes=2, model=39.07_36.32_61.35_61.50, label=best_Narayani_SA_model\n",
    "<li>drainageID=GA_Karnali_at_Benighat, majorID=GA, nstrikes=2, model=21.13_19.45_67.99_63.94, label=best_Karnali_SA_model\n",
    "<li>drainageID=GA_v01_OBJECTID1, majorID=GA, nstrikes=2, model=21.13_19.45_67.99_63.94, label=best_Karnali_SA_model\n",
    "<li>drainageID=BR_OBJECTID100, majorID=BR, nstrikes=2, model=36.34_34.61_43.15_54.67, label=best_SaptaKosi_SA_model\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This was the config setter for the REEC paper, it changes the output directory with labels for rank and ncycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_reec_config_for_model_type(drainageID, nstrikes, ncycle=None, rank=0):\n",
    "    '''\n",
    "    Sets up model config, changing melt output files directory, if needed.\n",
    "        drainageID : name of drainage where the model will be run, XX_river_at_pourpoint\n",
    "        nstrikes : 2 or 3 (MODICE strikes)\n",
    "        rank : model rank to use, counting backwards/forwards???\n",
    "        ncycle : if not None, this is the cycle number to look up and\n",
    "                use the best model for this cycle\n",
    "    Returns a dict with:\n",
    "        env : charis model config file\n",
    "        model : string with model to run, either \"Best\" or from the requested SA cycle\n",
    "        label : string to use for output filenames\n",
    "    '''\n",
    "    #on summit\n",
    "    #configFile = '/projects/brodzik/charis_ti_melt/calibration_modelEnv_config.ini'\n",
    "    # on worsley with sshfs\n",
    "    configFile = '/Users/brodzik/ipython_notebooks/charis/calibration_modelEnv_config.ini'\n",
    "    myEnv = ModelEnv(tileConfigFile=configFile)\n",
    "    \n",
    "    # parse the drainageID to decide on the best calibration basin models to use\n",
    "    majorID = drainageID[:2]\n",
    "    if majorID == \"IN\":\n",
    "        calibrationID = \"IN_Hunza_at_DainyorBridge\"\n",
    "    elif majorID == \"AM\":\n",
    "        calibrationID = \"AM_Vakhsh_at_Komsomolabad\"\n",
    "    elif majorID == \"SY\":\n",
    "        calibrationID = \"SY_Naryn_at_NarynTown\"\n",
    "    elif drainageID == \"GA_Narayani_at_Devghat\":\n",
    "        calibrationID = drainageID\n",
    "    elif drainageID == \"GA_Karnali_at_Benighat\":\n",
    "        calibrationID = drainageID\n",
    "    elif drainageID == \"GA_SaptaKosi_at_Chatara\":\n",
    "        calibrationID = drainageID\n",
    "    elif majorID == \"GA\":\n",
    "        calibrationID = \"GA_Karnali_at_Benighat\"\n",
    "    elif majorID == \"BR\":\n",
    "        calibrationID = \"GA_SaptaKosi_at_Chatara\"\n",
    "    else:\n",
    "        raise ValueError(\"ERROR: Skipping drainageID=%s, unknown majorID=%s\" % (drainageID, majorID))\n",
    "    \n",
    "    # Parse for the calibration basin short name\n",
    "    p = re.compile(r\"[A-Z]{2}_([A-Za-z]+)_\")\n",
    "    m = p.search(calibrationID)\n",
    "    shortName = m.group(1)\n",
    "    label = \"best_%s_SA_model\" % shortName\n",
    "\n",
    "    # For CycleXXX runs, change the location of output melt files to include the Cycle number\n",
    "    # Filenames will be exactly the same, just the output directories will be different\n",
    "    # For BestXXX runs, change the location of output melt files to include the Best model number\n",
    "    # Filenames will be exactly the same, just the output directories will be different\n",
    "    # This only works for REECv0 runs, should be generalized\n",
    "    p = re.compile(r'REECv0')\n",
    "\n",
    "    melt_type = ['snow_on_land_melt_by_elevation',\n",
    "                 'snow_on_ice_melt_by_elevation',\n",
    "                 'exposed_glacier_ice_melt_by_elevation']\n",
    "    \n",
    "    calibration_dir = \"%s/%s\" % (myEnv.tileConfig['model_top_dir'], \"calibrations_correct_cost\")\n",
    "\n",
    "    if not ncycle:\n",
    "        \n",
    "        # Use the best overall model, get it from the models file with best models\n",
    "        # by drainage and nstrikes\n",
    "        print(\"Prepping for model choice %d for drainageID=%s\" % (rank, drainageID),\n",
    "              file=sys.stderr)\n",
    "        \n",
    "        new_location = \"REECv0_ModelRank%03d\" % rank\n",
    "    \n",
    "        for i in melt_type:\n",
    "            myEnv.tileConfig['hypsometry'][i]['dir'] = p.sub(\n",
    "                new_location, myEnv.tileConfig['hypsometry'][i]['dir'])\n",
    "\n",
    "        params = \"DDFnbr=10mm_N100_M050\"\n",
    "        models_file = \"%s/%s.%dstr_%s.stats.best20.dat\" % (\n",
    "            calibration_dir, calibrationID, nstrikes, params)\n",
    "        models_df = pd.read_pickle(models_file)\n",
    "        model_str = models_df.iloc[rank].model\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Use the best model for this SA cycle number\n",
    "        # edit the output directory locations to match the cycle number\n",
    "        print(\"Prepping for Best model from cycle=%03d for drainageID=%s\" % (ncycle, drainageID),\n",
    "              file=sys.stderr)\n",
    "        \n",
    "        new_location = \"REECv0_Cycle%03d\" % ncycle\n",
    "    \n",
    "        for i in melt_type:\n",
    "            myEnv.tileConfig['hypsometry'][i]['dir'] = p.sub(\n",
    "                new_location, myEnv.tileConfig['hypsometry'][i]['dir'])\n",
    "            \n",
    "        # Read the SA cycle model results to get the best model for this cycle\n",
    "        params = \"DDFnbr=10mm_N100_M050\"\n",
    "        models_file = \"%s/%s.%dstr_%s.SA_summary.best20.dat\" % (\n",
    "            calibration_dir, drainageID, nstrikes, params)\n",
    "        models_df = pd.read_pickle(models_file)\n",
    "        model_str = models_df.at[ncycle, \"model\"]\n",
    "        \n",
    "    print(\"Using models from %s\" % models_file,\n",
    "          file=sys.stderr)\n",
    "            \n",
    "    print(\"Output locations will be:\", file=sys.stderr)\n",
    "    for i in melt_type:\n",
    "        print(\"%s: %s\" % (i, myEnv.tileConfig['hypsometry'][i]['dir']), file=sys.stderr)\n",
    "        \n",
    "    out = {'env':myEnv,\n",
    "           'majorID':majorID,\n",
    "           'calibrationID':calibrationID,\n",
    "           'model_str':model_str,\n",
    "           'label':label}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd BL_ChongKyzylSuu_at_KaraBatkak\n",
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"BL_ChongKyzylSuu_at_KaraBatkak.2001.0100m.modicev04_1strike.snow_on_land_area_by_elev.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = Hypsometry(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
